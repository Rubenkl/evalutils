from sklearn.metrics import accuracy_score

from evalutils import ClassificationEvaluation
from evalutils.io import CSVLoader
from evalutils.validators import ExpectedColumnNamesValidator


class {{ cookiecutter.package_name|capitalize }}(
{%- if cookiecutter.challenge_kind == "Classification" -%}
ClassificationEvaluation
{%- elif cookiecutter.challenge_kind == "Detection" -%}
DetectionEvaluation
{%- elif cookiecutter.challenge_kind == "Segmentation" -%}
SegmentationEvaluation
{%- endif -%}):
    def __init__(self):
        super().__init__(
            file_loader=CSVLoader(),
            validators=(
                ExpectedColumnNamesValidator(expected=("case", "class",)),
            ),
            join_key="case",
        )

    def score_aggregates(self):
        return {
            "accuracy_score": accuracy_score(
                self._cases["class_ground_truth"], self._cases["class_prediction"]
             ),
        }


if __name__ == "__main__":
    evaluation = {{ cookiecutter.package_name|capitalize }}()
    evaluation.evaluate()
